{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "universal-cloud",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/oak/stanford/groups/dpwall/computeEnvironments/micropheno/MicroPheno/')\n",
    "from make_representations.representation_maker import Metagenomic16SRepresentation, FastaRepresentations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import scipy.sparse\n",
    "from tqdm import tqdm\n",
    "BIOMARKER_DIR = '/home/groups/dpwall/briannac/sequence_based_biomarkers/results/generate_biomarkers/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "integral-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_unique_columns(M):\n",
    "    M = M.tocsc()\n",
    "    m, n = M.shape\n",
    "    if not M.has_sorted_indices:\n",
    "        M.sort_indices()\n",
    "    if not M.has_canonical_format:\n",
    "        M.sum_duplicates()\n",
    "    sizes = np.diff(M.indptr)\n",
    "    idx = np.argsort(sizes)\n",
    "    Ms = M@scipy.sparse.csc_matrix((np.ones((n,)), idx, np.arange(n+1)), (n, n))\n",
    "    ssizes = np.diff(Ms.indptr)\n",
    "    ssizes[1:] -= ssizes[:-1]\n",
    "    grpidx, = np.where(ssizes)\n",
    "    grpidx = np.concatenate([grpidx, [n]])\n",
    "    if ssizes[0] == 0:\n",
    "        counts = [np.array([0, grpidx[0]])]\n",
    "    else:\n",
    "        counts = [np.zeros((1,), int)]\n",
    "    ssizes = ssizes[grpidx[:-1]].cumsum()\n",
    "    for i, ss in tqdm(enumerate(ssizes)):\n",
    "        gil, gir = grpidx[i:i+2]\n",
    "        pl, pr = Ms.indptr[[gil, gir]]\n",
    "        dv = Ms.data[pl:pr].view(f'V{ss*Ms.data.dtype.itemsize}')\n",
    "        iv = Ms.indices[pl:pr].view(f'V{ss*Ms.indices.dtype.itemsize}')\n",
    "        idxi = np.lexsort((dv, iv))\n",
    "        dv = dv[idxi]\n",
    "        iv = iv[idxi]\n",
    "        chng, = np.where(np.concatenate(\n",
    "            [[True], (dv[1:] != dv[:-1]) | (iv[1:] != iv[:-1]), [True]]))\n",
    "        counts.append(np.diff(chng))\n",
    "        idx[gil:gir] = idx[gil:gir][idxi]\n",
    "    counts = np.concatenate(counts)\n",
    "    nu = counts.size - 1\n",
    "    uniques = M@scipy.sparse.csc_matrix((np.ones((nu,)), idx[counts[:-1].cumsum()],\n",
    "                                   np.arange(nu + 1)), (n, nu))\n",
    "    return uniques, idx[counts[:-1].cumsum()], counts[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "typical-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute person x biomarker matrix\n",
    "def SaveMatrices(asv_biomarker, biomarkers, dataset, biomarker_type):\n",
    "    sample_vs_asv = pd.read_table('/home/groups/dpwall/briannac/sequence_based_biomarkers/data/%s/sample_vs_asv.tsv' % dataset, index_col=0)\n",
    "    person_biomarker = scipy.sparse.csc_matrix(sample_vs_asv.transpose())*asv_biomarker\n",
    "    biomarker_exists  = [True for _ in biomarkers]\n",
    "        \n",
    "    _, no_ld_idx, _ = sparse_unique_columns(asv_biomarker)\n",
    "    no_ld_idx = sorted(no_ld_idx)\n",
    "\n",
    "    print(\"Number of biomarkers after LD filtering: \", len(no_ld_idx))\n",
    "\n",
    "        #np.save('%sperson_variant%d_condensed' %  (output_dir,order), person_biomarker)\n",
    "    print('Computing biomarker names...')\n",
    "\n",
    "        #asv_biomarker = scipy.sparse.csr_matrix(asv_biomarker[:,no_ld_idx])\n",
    "    person_biomarker = scipy.sparse.csr_matrix(person_biomarker[:,no_ld_idx])\n",
    "\n",
    "    is_abundant = ((person_biomarker>0).mean(axis=0)>.1).tolist()[0]\n",
    "    print(sum(is_abundant), ' biomarkers > 10% freq')\n",
    "    asv_biomarker = asv_biomarker[:,np.where(is_abundant)[0]]\n",
    "    person_biomarker = person_biomarker[:,np.where(is_abundant)[0]]\n",
    "\n",
    "    unique_idx_current = 0\n",
    "    current_idx = 0\n",
    "    with open(BIOMARKER_DIR + 'biomarker_names_%s_%s.txt' % (biomarker_type, dataset), 'w') as f:\n",
    "        for i,biomarker in tqdm(enumerate(biomarkers)):\n",
    "            if biomarker_exists[i]:  # If biomarker doesn't even exist, just skip.\n",
    "                if unique_idx_current==len(no_ld_idx):\n",
    "                    break\n",
    "                elif current_idx==no_ld_idx[unique_idx_current]:\n",
    "                    if is_abundant[unique_idx_current]: \n",
    "                        f.write(str(biomarker) + '\\n')\n",
    "                    unique_idx_current += 1\n",
    "                current_idx += 1\n",
    "    print(\"Writing to files...\")\n",
    "    scipy.sparse.save_npz(BIOMARKER_DIR + 'asv_vs_biomarker_%s_%s.npz' % (biomarker_type, dataset), asv_biomarker)  # Save sparse matrix of ASV x biomarker.\n",
    "    scipy.sparse.save_npz(BIOMARKER_DIR + 'sample_vs_biomarker_%s_%s.npz' % (biomarker_type, dataset), person_biomarker)  # Save sparse matrix of ASV x biomarker.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-archive",
   "metadata": {},
   "source": [
    "# Micropheno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "electric-holocaust",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "244it [00:00, 26012.51it/s]\n",
      "256it [00:00, 428981.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of biomarkers after LD filtering:  256\n",
      "Computing biomarker names...\n",
      "256  biomarkers > 10% freq\n",
      "Writing to files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "832it [00:00, 27292.19it/s]\n",
      "4096it [00:00, 511016.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of biomarkers after LD filtering:  4053\n",
      "Computing biomarker names...\n",
      "3595  biomarkers > 10% freq\n",
      "Writing to files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "775it [00:00, 21436.20it/s]\n",
      "65536it [00:00, 818807.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of biomarkers after LD filtering:  15816\n",
      "Computing biomarker names...\n",
      "9356  biomarkers > 10% freq\n",
      "Writing to files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "252it [00:00, 25114.40it/s]\n",
      "256it [00:00, 447952.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of biomarkers after LD filtering:  256\n",
      "Computing biomarker names...\n",
      "256  biomarkers > 10% freq\n",
      "Writing to files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "904it [00:00, 27181.85it/s]\n",
      "4096it [00:00, 543752.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of biomarkers after LD filtering:  3962\n",
      "Computing biomarker names...\n",
      "2855  biomarkers > 10% freq\n",
      "Writing to files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "904it [00:00, 22346.02it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of biomarkers after LD filtering:  13350\n",
      "Computing biomarker names...\n",
      "4878  biomarkers > 10% freq\n",
      "Writing to files...\n"
     ]
    }
   ],
   "source": [
    "for dataset in ['autism', 'obesity']:\n",
    "    for k in [4,6,8]:\n",
    "        seqs_file='/home/groups/dpwall/briannac/sequence_based_biomarkers/data/%s/seqs.fa' % dataset\n",
    "        \n",
    "        FastaRep=FastaRepresentations(seqs_file,label_modifying_func=lambda x: x.split('.')[0])\n",
    "        asv_biomarker=FastaRep.get_vector_rep(FastaRep.corpus, k,restricted=True)\n",
    "        \n",
    "        SaveMatrices(asv_biomarker, [i for i in range(np.shape(asv_biomarker)[1])], dataset, 'micropheno%s' % k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-providence",
   "metadata": {},
   "source": [
    "# 1 SBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "continent-parish",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "488it [00:00, 26149.76it/s]\n",
      "1121it [00:00, 527997.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of biomarkers after LD filtering:  1121\n",
      "Computing biomarker names...\n",
      "644  biomarkers > 10% freq\n",
      "Writing to files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "498it [00:00, 25084.83it/s]\n",
      "912it [00:00, 508603.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of biomarkers after LD filtering:  912\n",
      "Computing biomarker names...\n",
      "594  biomarkers > 10% freq\n",
      "Writing to files...\n"
     ]
    }
   ],
   "source": [
    "for dataset in ['autism', 'obesity']:\n",
    "    rdp = [record for record in SeqIO.parse('/home/groups/dpwall/briannac/sequence_based_biomarkers/data/%s/seqs_aligned_rdp.fa' % dataset, 'fasta')][:-1] \n",
    "    df = pd.DataFrame([list(r.seq.upper()) for r in rdp])\n",
    "    is_interesting = df.apply(lambda x: (len(set(x))>0) & (len(set(x).intersection(['A', 'T', 'C', 'G']))>0))\n",
    "\n",
    "    df = df[df.columns[is_interesting]]\n",
    "    df_A = df=='A'\n",
    "    df_A.columns = [str(c) + '_A' for c in df_A.columns]\n",
    "    df_T = df=='T'\n",
    "    df_T.columns = [str(c) + '_T' for c in df_T.columns]\n",
    "    df_G = df=='G'\n",
    "    df_G.columns = [str(c) + '_G' for c in df_G.columns]\n",
    "    df_C = df=='C'\n",
    "    df_C.columns = [str(c) + '_C' for c in df_C.columns]\n",
    "    df_gap = df=='-'\n",
    "    df_gap.columns = [str(c) + '_gap' for c in df_gap.columns]\n",
    "    df_sbb1 = pd.concat([df_A, df_C, df_T, df_G, df_gap], axis=1)\n",
    "    df_sbb1 = df_sbb1[df_sbb1.columns[(df_sbb1.mean()>0.0) & (df_sbb1.mean()<1.0)]]\n",
    "    df_sbb1 = df_sbb1[df_sbb1.columns[~df_sbb1.transpose().duplicated().values]]\n",
    "\n",
    "    df_sbb1 = pd.concat([df_A, df_C, df_T, df_G, df_gap], axis=1)\n",
    "\n",
    "    # Get rid of biomarkers at 100% frequency, 0% frequency, and in LD w/another.\n",
    "    df_sbb1 = df_sbb1[df_sbb1.columns[(df_sbb1.mean()>0.0) & (df_sbb1.mean()<1.0)]]\n",
    "    df_sbb1 = df_sbb1[df_sbb1.columns[~df_sbb1.transpose().duplicated().values]]\n",
    "\n",
    "    # Save sparse matrix of ASV x biomarker.\n",
    "    asv_biomarker = scipy.sparse.csc_matrix(df_sbb1)\n",
    "    SaveMatrices(asv_biomarker, df_sbb1.columns, dataset, 'sbb1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-invalid",
   "metadata": {},
   "source": [
    "# 1 SBB for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "respiratory-nevada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5249, 57)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:00, 26002.75it/s]\n",
      "57it [00:00, 275750.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of biomarkers after LD filtering:  57\n",
      "Computing biomarker names...\n",
      "34  biomarkers > 10% freq\n",
      "Writing to files...\n",
      "(12363, 46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [00:00, 25451.58it/s]\n",
      "46it [00:00, 245780.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of biomarkers after LD filtering:  46\n",
      "Computing biomarker names...\n",
      "37  biomarkers > 10% freq\n",
      "Writing to files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in ['autism', 'obesity']:\n",
    "    rdp = [record for record in SeqIO.parse('/home/groups/dpwall/briannac/sequence_based_biomarkers/data/%s/seqs_aligned_rdp.fa' % dataset, 'fasta')][:-1] \n",
    "    df = pd.DataFrame([list(r.seq.upper()) for r in rdp])\n",
    "    is_interesting = df.apply(lambda x: (len(set(x))>0) & (len(set(x).intersection(['A', 'T', 'C', 'G']))>0))\n",
    "\n",
    "    df = df[df.columns[is_interesting]]\n",
    "    df_A = df=='A'\n",
    "    df_A.columns = [str(c) + '_A' for c in df_A.columns]\n",
    "    df_T = df=='T'\n",
    "    df_T.columns = [str(c) + '_T' for c in df_T.columns]\n",
    "    df_G = df=='G'\n",
    "    df_G.columns = [str(c) + '_G' for c in df_G.columns]\n",
    "    df_C = df=='C'\n",
    "    df_C.columns = [str(c) + '_C' for c in df_C.columns]\n",
    "    df_gap = df=='-'\n",
    "    df_gap.columns = [str(c) + '_gap' for c in df_gap.columns]\n",
    "    df_sbb1 = pd.concat([df_A, df_C, df_T, df_G, df_gap], axis=1)\n",
    "    df_sbb1 = df_sbb1[df_sbb1.columns[(df_sbb1.mean()>0.0) & (df_sbb1.mean()<1.0)]]\n",
    "    df_sbb1 = df_sbb1[df_sbb1.columns[~df_sbb1.transpose().duplicated().values]]\n",
    "    df_sbb1 = pd.concat([df_A, df_C, df_T, df_G, df_gap], axis=1)\n",
    "\n",
    "    # Get rid of biomarkers at 100% frequency, 0% frequency, and in LD w/another.\n",
    "    df_sbb1 = df_sbb1[df_sbb1.columns[(df_sbb1.mean()>0.0) & (df_sbb1.mean()<1.0)]]\n",
    "    df_sbb1 = df_sbb1[df_sbb1.columns[~df_sbb1.transpose().duplicated().values]]\n",
    "    df_sbb1 = df_sbb1[df_sbb1.columns[::20]] # JUST 100 COLUMNS FOR TESTING\n",
    "    print(np.shape(df_sbb1))\n",
    "    # Save sparse matrix of ASV x biomarker.\n",
    "    asv_biomarker = scipy.sparse.csc_matrix(df_sbb1)\n",
    "    SaveMatrices(asv_biomarker, df_sbb1.columns, dataset, 'sbb1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-tuition",
   "metadata": {},
   "source": [
    "# OTUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "narrow-compilation",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-caf1977bb971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0motu_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0masv_biomarker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsc_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mSaveMatrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masv_biomarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0motu_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'otu%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-e296f7d5ef10>\u001b[0m in \u001b[0;36mSaveMatrices\u001b[0;34m(asv_biomarker, biomarkers, dataset, biomarker_type)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msample_vs_asv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/groups/dpwall/briannac/sequence_based_biomarkers/data/%s/sample_vs_asv.tsv'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mperson_biomarker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsc_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_vs_asv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0masv_biomarker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mbiomarker_exists\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbiomarkers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_ld_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse_unique_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masv_biomarker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not iterable"
     ]
    }
   ],
   "source": [
    "for dataset in ['autism', 'obesity']:\n",
    "    for similarity in [90, 95, 97, 99]:\n",
    "        otu_mapping = pd.read_table('/home/groups/dpwall/briannac/sequence_based_biomarkers/results/generate_biomarkers/otu_asv_map_%i_%s.txt' % (similarity, dataset), header=None)\n",
    "        otu_dict = {otu:idx for idx, otu in enumerate(np.unique(otu_mapping[1]))}\n",
    "        otu_mapping[1] = [otu_dict[i] for i in otu_mapping[1]]\n",
    "        mat = np.zeros((len(otu_mapping), len(otu_dict)))\n",
    "        for i, otu_id in enumerate(otu_mapping[1]):\n",
    "            mat[i][otu_id] = 1\n",
    "        asv_biomarker = scipy.sparse.csc_matrix(mat)\n",
    "        SaveMatrices(asv_biomarker, otu_dict.keys, dataset, 'otu%s' % similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-jersey",
   "metadata": {},
   "source": [
    "# ASVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-tampa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['autism', 'obesity']:\n",
    "    sample_vs_asv = pd.read_table('/home/groups/dpwall/briannac/sequence_based_biomarkers/data/%s/sample_vs_asv.tsv' % dataset, index_col=0)\n",
    "\n",
    "    # Save sparse matrix of ASV x biomarker.\n",
    "    asv_biomarker = scipy.sparse.csc_matrix(np.identity(len(sample_vs_asv)))\n",
    "    SaveMatrices(asv_biomarker, sample_vs_asv.index, dataset, 'asv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-bread",
   "metadata": {},
   "source": [
    "# Taxa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in ['autism', 'obesity']:\n",
    "    annotations = pd.read_table('/home/groups/dpwall/briannac/sequence_based_biomarkers/data/%s/asv_vs_taxa_annotation.tsv' % dataset, index_col=0)\n",
    "    sample_vs_asv = pd.read_table('/home/groups/dpwall/briannac/sequence_based_biomarkers/data/%s/sample_vs_asv.tsv' % dataset, index_col=0)\n",
    "    annotations['Kingdom'] = ['k_' +a for a in annotations['Kingdom']]\n",
    "    annotations['Phylum'] = ['p_' +a for a in annotations['Phylum']]\n",
    "    annotations['Class'] = ['c_' +a for a in annotations['Class']]\n",
    "    annotations['Order'] = ['o_' +a for a in annotations['Order']]\n",
    "    annotations['Family'] = ['f_' +a for a in annotations['Family']]\n",
    "    annotations['Genus'] = ['g_' +a for a in annotations['Genus']]\n",
    "    taxa = np.unique(np.concatenate(annotations.values))\n",
    "    taxa_df = pd.DataFrame(np.zeros((len(annotations), len(taxa))))\n",
    "    taxa_df.columns = taxa\n",
    "    taxa_df.index = annotations.index\n",
    "    taxa_df = taxa_df[[c for c in taxa_df.columns if 'unclassified' not in c]]\n",
    "    for row in annotations.iterrows():\n",
    "        taxa_df.loc[row[0],list([r for r in row[1].values if 'unclassified' not in r])]  = 1\n",
    "        \n",
    "        \n",
    "    # Save sparse matrix of ASV x biomarker.\n",
    "    asv_biomarker = scipy.sparse.csc_matrix(taxa_df)\n",
    "    SaveMatrices(asv_biomarker, taxa_df.columns, dataset, 'taxa')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_36_env",
   "language": "python",
   "name": "py_36_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
